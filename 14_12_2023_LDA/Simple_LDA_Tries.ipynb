{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Comment Number</th>\n",
       "      <th>Comment Text</th>\n",
       "      <th>Star Count</th>\n",
       "      <th>Seller Info</th>\n",
       "      <th>Any Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cok kisa surede cok  saglam geldi..urunun gors...</td>\n",
       "      <td>5</td>\n",
       "      <td>bu ürünü Hızlıgitti satıcısından aldı.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Kullanımı kolay , zaman ayarlamasını yapıyorsu...</td>\n",
       "      <td>5</td>\n",
       "      <td>bu ürünü EMC&amp;BİLİSİM&amp;TEKN satıcısından aldı.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4 kişilik cekırdek bır aileye yeterli bence.4 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>bu ürünü Hepsiburada satıcısından aldı.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Ürünü çok beğendim daha önce almadığım için pi...</td>\n",
       "      <td>5</td>\n",
       "      <td>bu ürünü Hızlıgitti satıcısından aldı.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Kanat yaptım çok güzeldi çok beğendim mükemmel...</td>\n",
       "      <td>5</td>\n",
       "      <td>bu ürünü Hızlıgitti satıcısından aldı.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Page Number Comment Number  \\\n",
       "0           1              1   \n",
       "1           1              2   \n",
       "2           1              3   \n",
       "3           1              4   \n",
       "4           1              5   \n",
       "\n",
       "                                        Comment Text Star Count  \\\n",
       "0  Cok kisa surede cok  saglam geldi..urunun gors...          5   \n",
       "1  Kullanımı kolay , zaman ayarlamasını yapıyorsu...          5   \n",
       "2  4 kişilik cekırdek bır aileye yeterli bence.4 ...          5   \n",
       "3  Ürünü çok beğendim daha önce almadığım için pi...          5   \n",
       "4  Kanat yaptım çok güzeldi çok beğendim mükemmel...          5   \n",
       "\n",
       "                                    Seller Info Any Info  \n",
       "0        bu ürünü Hızlıgitti satıcısından aldı.      NaN  \n",
       "1  bu ürünü EMC&BİLİSİM&TEKN satıcısından aldı.      NaN  \n",
       "2       bu ürünü Hepsiburada satıcısından aldı.      NaN  \n",
       "3        bu ürünü Hızlıgitti satıcısından aldı.      NaN  \n",
       "4        bu ürünü Hızlıgitti satıcısından aldı.      NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk \n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('comment.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65 entries, 0 to 64\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Page Number     65 non-null     object\n",
      " 1   Comment Number  65 non-null     object\n",
      " 2   Comment Text    65 non-null     object\n",
      " 3   Star Count      65 non-null     object\n",
      " 4   Seller Info     65 non-null     object\n",
      " 5   Any Info        5 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Page Number  Comment Number  \\\n",
      "0             1               1   \n",
      "1             1               2   \n",
      "2             1               3   \n",
      "3             1               4   \n",
      "4             1               5   \n",
      "5             1               6   \n",
      "6             1               7   \n",
      "7             1               8   \n",
      "8             1               9   \n",
      "9             1              10   \n",
      "10  Page Number  Comment Number   \n",
      "11            2               1   \n",
      "12            2               2   \n",
      "13            2               3   \n",
      "14            2               4   \n",
      "15            2               5   \n",
      "16            2               6   \n",
      "17            2               7   \n",
      "18            2               8   \n",
      "19            2               9   \n",
      "\n",
      "                                         Comment Text  Star Count  \\\n",
      "0   cok kisa surede cok saglam geldiurunun gorsell...           5   \n",
      "1   kullanımı kolay zaman ayarlamasını yapıyorsunu...           5   \n",
      "2   4 kişilik cekırdek bır aileye yeterli bence4 a...           5   \n",
      "3   ürünü beğendim önce almadığım pişman oldum pat...           5   \n",
      "4     kanat yaptım güzeldi beğendim mükemmel bir ürün           5   \n",
      "5   pişirme modlarının ayrıntılı yazdığı bir kitap...           5   \n",
      "6   bende direnenlerdenim bunca zaman almamışım 3 ...           5   \n",
      "7   ürün gerçekten güzel memnunum eti tavuğu patat...           5   \n",
      "8   ürün paketlemesi olsun kargo teslimatının gerç...           5   \n",
      "9   güzel pratik em hoşuma giden sosilerin yağsız ...           5   \n",
      "10                                       comment text  Star Count   \n",
      "11  valla patates tavuk vs yaptık gayet iyi 2-3 ki...           5   \n",
      "12  ürüne diyecek söz yok markası belli kargo hızl...           5   \n",
      "13  önce almadım pişman oldum epey araştırdım ürün...           5   \n",
      "14  philips airfrier ı kalitesini bilerek anneme a...           5   \n",
      "15  hızlı sağlam sorunsuz bir şekilde geldi ürünü ...           5   \n",
      "16  4 kişilik bir aile kapasitesi düşük markaya gö...           5   \n",
      "17  markası zaten şüphesiz tavsiye üstüne aynı ürü...           5   \n",
      "18  güzel zahmetsiz bir ürün tavuk yaptım kestane ...           4   \n",
      "19  bende xxl olan modeli var bunu anneme hediye o...           5   \n",
      "\n",
      "                                     Seller Info  Any Info  \n",
      "0         bu ürünü Hızlıgitti satıcısından aldı.       NaN  \n",
      "1   bu ürünü EMC&BİLİSİM&TEKN satıcısından aldı.       NaN  \n",
      "2        bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "3         bu ürünü Hızlıgitti satıcısından aldı.       NaN  \n",
      "4         bu ürünü Hızlıgitti satıcısından aldı.       NaN  \n",
      "5        bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "6        bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "7        bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "8        bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "9        bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "10                                   Seller Info  Any Info  \n",
      "11        bu ürünü Hızlıgitti satıcısından aldı.       NaN  \n",
      "12       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "13       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "14       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "15       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "16       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "17       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "18       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n",
      "19       bu ürünü Hepsiburada satıcısından aldı.       NaN  \n"
     ]
    }
   ],
   "source": [
    "WPT = nltk.WordPunctTokenizer()\n",
    "stop_word_list = nltk.corpus.stopwords.words(\"turkish\")\n",
    "\n",
    "\n",
    "docs = data[\"Comment Text\"]\n",
    "docs = docs.map(lambda x: re.sub('[,\\.!?();:$%&#\"]', '', x))\n",
    "docs = docs.map(lambda x: x.lower())\n",
    "docs = docs.map(lambda x: x.strip())\n",
    "\n",
    "def token(values):\n",
    "    filtered_words =  [word for word in values.split() if word not in stop_word_list]\n",
    "    not_stopword_doc = \" \".join(filtered_words)\n",
    "    return not_stopword_doc\n",
    "\n",
    "docs = docs.map(lambda x: token(x))\n",
    "data[\"Comment Text\"] = docs\n",
    "\n",
    "print(data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDoc = data[\"Comment Text\"].values.tolist()\n",
    "dataStar = data[\"Star Count\"].values.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataDoc,dataStar, test_size=0.3 , random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2),max_df=0.9, min_df=5)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('güzel', 12),\n",
       " ('ürün', 11),\n",
       " ('bir', 9),\n",
       " ('tavuk', 6),\n",
       " ('oldu', 5),\n",
       " ('pratik', 5),\n",
       " ('kişilik', 5),\n",
       " ('gayet', 5),\n",
       " ('yeterli', 5),\n",
       " ('harika', 5),\n",
       " ('ürünü', 5),\n",
       " ('iyi', 5),\n",
       " ('comment', 5),\n",
       " ('text', 5),\n",
       " ('patates', 4),\n",
       " ('tek', 4),\n",
       " ('hızlı', 4),\n",
       " ('memnun', 4),\n",
       " ('ederim', 4),\n",
       " ('pat', 4)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_counts = Counter([word for line in X_train for word in line.split(' ')])\n",
    "\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x : x[1], reverse=True)[:20]\n",
    "\n",
    "most_common_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LineerSVC accuracy is 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#lineersvc\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "SVC_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "SVC_pipeline.fit(X_train_tfidf, y_train)\n",
    "prediction = SVC_pipeline.predict(X_test_tfidf)\n",
    "print('LineerSVC accuracy is {}'.format(accuracy_score(y_test, prediction)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy=0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alper\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#stochastic gradient descent\n",
    "model2 = OneVsRestClassifier(SGDClassifier(loss = 'hinge', penalty = 'elasticnet', max_iter = 5))\n",
    "model2.fit(X_train_tfidf, y_train)\n",
    "print (\"SGD Accuracy={}\".format(accuracy_score(y_test, model2.predict(X_test_tfidf))))\n",
    "sgdpred = accuracy_score(y_test, model2.predict(X_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "güzel göre düşük bir markaya aile kişilik fiyat kapasitesi makinaya teslimat kötü süper günü aldım et kargo çalışmıyor düşeni çıkıp almadığım gönderirken guzel dakika bence4 20 bitti 10 muhteşem kişi\n",
      "Topic 1:\n",
      "kargo tavuk mutfağım alsam küçüktü yeterli hızlıydı ürüne gelir söz günde yaptık büyük patateskestane oldu gelmez olacakmış belli markası kişilik hızlı xxl diyecek gayet marka ederim pratik almamak tavsiye teslim\n",
      "Topic 2:\n",
      "gücü kanat cok çizik düğmeye çıktı oldugum yeni puşmemisti haliyle size taşıma ic aileler tariflere şimdi doğramak 12 bir kullandıktan kitapçık biber mutlaka hediyesi sonra sıcaklığı durumda kuvvetli gelmez hediye\n",
      "Topic 3:\n",
      "koydumhizli kapatıp nerdeyse makinada koymayin yaptı iki marka hacım kalın vs güzel günde patatesin çıkmıyor surede teslimat oldugum kullandim ardından sağlam urun ic text em sökülmüş epey anneme markası beyler\n",
      "Topic 4:\n",
      "ürün kaliteli yaptım aldım bekliyoruz serviste kanat iyi sonuç tavsiye almadım iki arızalandı philips bir patates şimdi tavuk yakışmadı beğendim araştırdım pişman kullandık güzeldi tek şekilde önce sepet markası börek\n",
      "Topic 5:\n",
      "geldiurunun bakıp ben muhteşem markası sıgar araştırdım eti taşıma gorsellerinin saglayamiyorum geliyor ürüne henüz arızalandı haliyle olcuyu mantar direnenlerdenim cekırdek çatlak köfteyi günde var uyduğunuz kötü makina olsun kişilik yapıyorsunuz\n",
      "Topic 6:\n",
      "harika güzel uyduğunuz kızarttım ürün fırsatım geliyor tek yemekler zahmetsiz tariflere kavurdum yaptım kullanma oldu bir rahatsız resizandsından kestane henüz gürültü patates tavuk müthiş olduğum sürece tasarruflu konu oluyor geldiginde\n",
      "Topic 7:\n",
      "almadım bır harikaaaa adet bence4 cekırdek aileye yeterli ölçüdepatates oldugum güzelmiş budu sıgar tavuk kaldık kişilik alın kaşığı oluyor mükemmel cok hepsini sepet kaldım dedim sut haznesi kirleniyoo yaptık yemek\n",
      "Topic 8:\n",
      "biber durumda olur üzerinde kutu atılmıyor kullandıktan olduk yıldız eşyalar cok uygun valla yapıyorum paketlenmesinden börek derdi haliyle hasarsız net modellerdeki alsam performansından internetten koymayin aynı ölçüdepatates makinada sonuçlar bırakılmamalı\n",
      "Topic 9:\n",
      "memnun oldum teşekkür ederim iddia anneme pisiremez marka kutu philips tartışmasız paketlemesi yıldız iyi ekstra modlarının eşyalar şef metale saglayamiyorum ediyorumairfry bayııldıımm tavsiye tavuğu bunun yok keşke hazırlayabiliyor tek hepsini\n",
      "Topic 10:\n",
      "kullanım muhteşem yemek yorumum sonrası bitti lk derdi bayııldıımm jullanip model patatesi puan metale yapıyorsunuz kutudan eşime kullanınca şüphesiz yapacağim al olayı şubede oluyor disini mutfağım patates cekırdek bende gündür\n",
      "Topic 11:\n",
      "urun bir çalısmiyor yaptık jullanip gönderim köfte esince disini tecrübe yorum kuruttu biraz puşmemisti çizik oldugum ürünün çi börek kullandim ti üzerinden mutsuz patates bölgede yazlik saglayamiyorum şuan açtığınızda ürüne\n",
      "Topic 12:\n",
      "teşekkürler kılavuzu iyi alabilimisimtek 34 çinde yok kullanma ben yaptım kaşığı almamışım gelir em herseyi doğum ayarlamasını kavurdum köfte kullanım örneğin önce eve düğmeye esince oldukitapcigi saglam sürüyorsunuz üzerine cihaz\n",
      "Topic 13:\n",
      "beklediğimizden kofte kötü alınca net kargo çinde bırakılmamalı oldum iyi temizlik yeni hazır mutlaka teşekkürler kaşığı lazım herhangi çıktı aldık puşmemisti denememicok küçüktü üzerine eşlerinize airfrier urun aparat gelir arızalandı\n",
      "Topic 14:\n",
      "10 cok iyi puan üzerinden icin kadar anlamanuz olcuyu durumda olmamasi gorsellerinin denememicok geldiurunun koyup surede yikayip hak guzel kisa resmini lt lik saglam metale direk biber dakika kötüinternetten 12\n",
      "Topic 15:\n",
      "xxl bunu var aldım anneme seviyorsan hediye modeli kullanışlı yeterli bende kişilik olan olarak saglam önce aileler ideal ediyor erkek surede tipinin cok ben et kuru neyse sıkıntı marka paketlemesi\n",
      "Topic 16:\n",
      "ederim philips markası keşke teşekkür 34 olsun örneğin bırakılmamalı pat hızlıydı önce çi alsaydım tek tür kullanma yapacağim performansından öğrenmek rahatsız olduğu geldiğinden lk patatesi patlıcan pişman kalitesini normal koydumhizli\n",
      "Topic 17:\n",
      "text comment açtığınızda patlıcan etmeksizin kızartma yapılmadan yorum durumda teslim alabilimisimtek öğrenmek kötüinternetten tariflere atılmıyor olan kızarmış mantar düşeni üstüne elde geldiurunun modlarının alın ürününü henüz taşıma oluyor kuru ettim\n",
      "Topic 18:\n",
      "güzel pratik hızlıca kızartıyoruz patates kurutuyor bi gerekiyor yemekleri patatesleri ekmek tavuk normal valla biraz yoksa alet yaptık vs iyi hazırlayabiliyor oluyor kişilik gayet kalın alsaydım memnun hızlı sonuçlar comment\n",
      "Topic 19:\n",
      "text comment iç yazikki okumalı beğendim yanı tek atılmıyor mutlaka çıkıp alacaklar anlamanuz makinaya anneme kullandık bilerek bunun sonrası sonra pat haznesi kötü denememicok yapacağim metale ürünü aileye ekstra edilmiş\n",
      "Topic 20:\n",
      "ürün şekilde pratik giden küçük yağsız geldiğinden em pismesi elektronik iade bozuk sosilerin teşekkürler hacım sıkıntılı anneme olarak saglam mükemmel süper kere lütfen modlarının hoşuma iyi fabrikasyon düşük güzel alıyorsunuz\n",
      "Topic 21:\n",
      "net lazım eve yağ in kullandıktan yapıyorsunuz sonra yapıyorum oluşturdum olarak 34 serviste yorum yazan alıcı patatesi fırsatım yoksa paketlenmesinden iade düşeni yemek gücü kullanım oldugum eşyalar direk satıcıda diyecek\n",
      "Topic 22:\n",
      "ürün gerçekten bir tavsiye güzel oldu kişilik kaldık bile kargo ederim olsun olarak 20 üzerinde eşime turkey kitapçık makina memnun oluşturdum memnunum patatesi pişirme mutlaka yemekler yeterli kargolama eti ideal\n",
      "Topic 23:\n",
      "pat olduğu ürün tekrar olsun talebi lütfen çatlak gönderirken üç ekstra sonrada hazne elektronik satıcı naylon döngüye anlaşılmış alıcı gücü yapılmadan sonra uygun iş tercihiniz bırakılmamalı naylona kutudan eşyalar herhangi\n",
      "Topic 24:\n",
      "ürün güzel ürünü üzerine tepsiyi bozuk paketlenmesinden philips hızlı sonra kargo kullanımı kaldım kuvvetli gündür örneğin göndermişler kolay süreyi gün açılmamış zaman patatesin açtığınızda olduğu 20 düğmeye ayarlamasını kapatıp keyfi\n",
      "Topic 25:\n",
      "etmeksizin kaldım olması yeterli fark et iki türkiyede gerekiyor kişi evde şuan gayet güzel temizlik kolay dedim sebze alıcı hacmi ambalajı tavuk önce başka sepet turkey giden memnun ardından gönderirken\n",
      "Topic 26:\n",
      "bir tek oldu elde direnenlerdenim yeterli yada model cikti bende 41 içinde patates herseyi lt harika kişilik yikayabilisiniz aldım pratik mantar sıkıntı ayrıca bunca tavuk yok neyse üst patlıcan aparat\n",
      "Topic 27:\n",
      "herşey kızartıyoruz icin gün gönderilmesi anlaşılmış yaptık herseyi pişman gorsellerinin sonuçlar kapatıp alıcı iki almamak pat ürünü kestane bir önce tür tasarruflu kuruttu adet herkese ederim disini esince teşekkürler zaten\n",
      "Topic 28:\n",
      "kullanınca alırken kaldım başında içindeydim alınca keşke lazım pratikhızlı tereddüt iyi alsaydım dedim sıkıntılı herşey gün vs kullandim kutudan rahatsız pişman şimdi dakika tür çıkıp değişim fark puşmemisti kullandıktan seferde\n",
      "Topic 29:\n",
      "kullanımı gayet kullandım hızlı güzel bir pratik temizliği sorunsuz deneyim pratikhızlı ürünü performansından makinaya memnunum pisiremez sağlam text şekilde geldi hazır hacmindeki lazım resmini çatlak ürüne yazdığı comment airfrier çıkışı\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def train_lda_model(data, n_topics=30):\n",
    "    # Count vectorization\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=1, max_features=10000)\n",
    "    tf = tf_vectorizer.fit_transform(data)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    # LDA model\n",
    "    lda = LDA(n_components=n_topics, max_iter=5, learning_method='online', learning_offset=50., random_state=0)\n",
    "    lda.fit(tf)\n",
    "\n",
    "    return lda, tf, tf_feature_names  # Include tf in the return to access it later\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "# Example usage:\n",
    "lda_model, tf_matrix, tf_feature_names = train_lda_model(dataDoc)\n",
    "display_topics(lda_model, tf_feature_names, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[0;32m      3\u001b[0m panel \u001b[38;5;241m=\u001b[39m pyLDAvis\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mprepare(lda,tf, tf_vectorizer, mds \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsne\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(lda,tf, tf_vectorizer, mds = 'tsne' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
